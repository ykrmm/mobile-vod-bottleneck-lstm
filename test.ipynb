{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test and visualize Deeplomatics Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A \n",
    "from datasets import Deeplomatics\n",
    "from datasets import draw_rect\n",
    "from torchvision import models\n",
    "from my_utils import collate_fn\n",
    "import torchvision.transforms.functional as TF\n",
    "from my_models import eval_mAP,eval_accuracy,MetricBuilder\n",
    "import torch\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gpu = 3\n",
    "device  = torch.device(\"cuda:\"+str(gpu) if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DATASET_DIR = '/share/DEEPLEARNING/datasets/deeplomatics'\n",
    "LOAD_DIR = '/share/homes/karmimy/deeplomatics/save_model/image_deeplo'\n",
    "dir = '11'\n",
    "model_name = 'deeplo_image.pt'\n",
    "LOAD_PT = os.path.join(LOAD_DIR,dir,model_name)\n",
    "model = torch.load(LOAD_PT,map_location=device)\n",
    "print('')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = Deeplomatics(DATASET_DIR,image_set='test',normalize=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset, batch_size=4,shuffle=True,drop_last=True,collate_fn=collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img,targets = dataset.__getitem__(0)\n",
    "true_bbox,true_label = targets['boxes'],targets['labels']\n",
    "x = torch.unsqueeze(img,0).to(device)\n",
    "x = TF.resize(x,(512,512)) \n",
    "d = model(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d[0].size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x.size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DATASET_DIR = '/share/DEEPLEARNING/datasets/deeplomatics'\n",
    "LOAD_DIR = '/share/homes/karmimy/deeplomatics/save_model/image_deeplo'\n",
    "dir = '9'\n",
    "model_name = 'deeplo_image.pt'\n",
    "LOAD_PT = os.path.join(LOAD_DIR,dir,model_name)\n",
    "device  = torch.device(\"cuda:\"+str(gpu) if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device  = torch.device(\"cuda:\"+str(gpu) if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(LOAD_PT,map_location=device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NUMBER_OF_EXAMPLE = 5\n",
    "PRINT = True\n",
    "LIMIT = False\n",
    "n_data = len(dataset)\n",
    "ind = np.arange(n_data)\n",
    "i_ex = np.random.choice(ind, size=NUMBER_OF_EXAMPLE, replace=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in i_ex : \n",
    "    fig = plt.figure()\n",
    "    model.eval()\n",
    "    img,targets = dataset.__getitem__(i)\n",
    "    true_bbox,true_label = targets['boxes'],targets['labels']\n",
    "    x = torch.unsqueeze(img,0).to(device)\n",
    "    d = model(x)\n",
    "    bbox = d[0]['boxes']\n",
    "    label = d[0]['labels']\n",
    "    plt.title('Image'+str(i))\n",
    "    plt.xlabel('True label'+str(true_label)+'; Label pred:'+str(label))\n",
    "    print('Label pred',label)\n",
    "    print('True label',true_label)\n",
    "    img = img.transpose_(0,2).transpose_(0,1)\n",
    "\n",
    "    binks = draw_rect(img.detach().cpu().numpy(),bbox.detach().cpu().numpy())\n",
    "    plt.imshow(binks)\n",
    "    plt.savefig('./results/'+str(i)+'.jpg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "metric_fn = MetricBuilder.build_evaluation_metric(\"map_2d\", async_mode=False, num_classes=2)\n",
    "for i,(images,targets) in enumerate(dataloader_test):\n",
    "    \n",
    "    if i > NUMBER_OF_EXAMPLE and LIMIT:\n",
    "        break\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k,v in t.items()} for t in targets] \n",
    "    pred_dict = model(images)\n",
    "    if PRINT : \n",
    "        print('----------------------------------------------------------------')\n",
    "        print('PRED DICT BOXES:',pred_dict[0]['boxes'],'|||| LABEL:',pred_dict[0]['labels'],'...')\n",
    "        print('****************************************************************')\n",
    "        print('GROUND TRUTH:',targets[0]['boxes'],'|||| LABEL:',targets[0]['labels'],'...')\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('\\n\\n')\n",
    "        metric_fn= convert_for_eval(metric_fn,pred_dict,targets) # also add predictions for the metric in this function "
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compute PASCAL VOC metric\n",
    "print(f\"VOC PASCAL mAP: {metric_fn.value(iou_thresholds=0.5, recall_thresholds=np.arange(0., 1.1, 0.1))['mAP']}\")\n",
    "\n",
    "# compute PASCAL VOC metric at the all points\n",
    "print(f\"VOC PASCAL mAP in all points: {metric_fn.value(iou_thresholds=0.5)['mAP']}\")\n",
    "\n",
    "# compute metric COCO metric\n",
    "print(f\"COCO mAP: {metric_fn.value(iou_thresholds=np.arange(0.5, 1.0, 0.05), recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy='soft')['mAP']}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "img,target = dataset.__getitem__(12)\n",
    "pred_dict = model(img.unsqueeze(0).to(device))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img.size()\n",
    "plt.imshow(img.transpose_(0,2).transpose_(0,1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "boxes = pred_dict[0]['boxes']\n",
    "label = pred_dict[0]['labels']\n",
    "print('LABEL',label)\n",
    "binks = draw_rect(img.detach().cpu().numpy(),boxes)\n",
    "plt.imshow(binks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
   }
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}